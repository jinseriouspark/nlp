{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영어를 각 나라의 단어로 번역하기.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FTlqgoWqtzC",
        "colab_type": "text"
      },
      "source": [
        "## 문자-단위 RNN 으로 이름 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qShIwiCmpujB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import unicodedata\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22VImIfsTQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_letters = string.ascii_letters + \".,;'-\"\n",
        "n_letters = len(all_letters) + 1 # EOS  기호를 추가하여 갯수를 센다"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ1DDIXqs9b9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3cc3621f-90b5-46dc-b153-185e3f1a6294"
      },
      "source": [
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "  if unicodedata.category(c) != 'Mn'\n",
        "  and c in all_letters\n",
        "  )\n",
        "\n",
        "#  파일을 읽어 줄 단위로 분리\n",
        "def readLines(filename):\n",
        "  lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
        "  return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "# 각 언어의 이름 목록인 category_lines 사전 생성\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "for filename in findFiles('/content/drive/My Drive/korean_embedding/raw_data/data/data/names/*.txt'):\n",
        "  category = os.path.splitext(os.path.basename(filename))[0]\n",
        "  all_categories.append(category)\n",
        "  lines = readLines(filename)\n",
        "  category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n",
        "if n_categories == 0:\n",
        "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
        "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
        "        'the current directory.')\n",
        "\n",
        "print('# categories:', n_categories, all_categories)\n",
        "print(unicodeToAscii(\"O'Néàl\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# categories: 18 ['Vietnamese', 'Dutch', 'Portuguese', 'Greek', 'Irish', 'French', 'Japanese', 'Scottish', 'Italian', 'Russian', 'Chinese', 'Spanish', 'English', 'Arabic', 'Polish', 'Korean', 'German', 'Czech']\n",
            "O'Neal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luuq9lcq9Pap",
        "colab_type": "text"
      },
      "source": [
        "## 네트워크 생성\n",
        "- RNN 이 다른 입력들과 연결되는 category tensor 를 추가 인자로 가질 수 있도록 확장\n",
        "- category tensor 는 문자 입력과 마찬가지로 one-hot 벡터\n",
        "- 출력물이 다음 문자의 예측 확률로 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQlJqzR39Grt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # 카테고리 , 인풋, 히든 정보를 모두 합침\n",
        "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
        "\n",
        "        # hidden & output 을 합쳐 하나의 output 으로 추가 생성\n",
        "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
        "        self.dropout = nn.Dropout(0.1) # 0.1 수준으로 드롭아웃\n",
        "        self.softmax = nn.LogSoftmax(dim=1) # 활성화 함수 소프트맥스 씌워주는 역할\n",
        "\n",
        "    def forward(self, category, input, hidden):\n",
        "        input_combined = torch.cat((category, input, hidden), 1)\n",
        "        hidden = self.i2h(input_combined)\n",
        "        output = self.i2o(input_combined)\n",
        "        output_combined = torch.cat((hidden, output), 1)\n",
        "        output = self.o2o(output_combined)\n",
        "        output = self.dropout(output)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmIA7sMo-MOB",
        "colab_type": "text"
      },
      "source": [
        "## 학습\n",
        "- (category - line) 무작위 쌍을 얻음\n",
        "- 각 시점마다 (학습 단어의 문자 마다) \n",
        "  - input :  (언어, 현재 문자, 은닉 상태 ) category, input, hidden\n",
        "  - output : (다음 문자, 다음 은닉 상태)  output, hidden\n",
        "- 각 시점마다 현재 문자에서 다음 문자를 예측하기 때문에, 문자 쌍은 한 줄(하나의 이름) 에서 연속된 문자 그룹\n",
        "  - 예: ABCE<EOS> 의 경우, (A,B), (B, C), (C, E), (E, <EOS>) 로 생성\n",
        "- category 텐서는 1 x n_categories 크기의 원 핫 텐서로 생성됨\n",
        "  - 모든 시간 단계 (시점) 에서 네트워크에 전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJgf7EFW-LTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# 목록에서 무작위 아이템 반환\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "# 임의의 category 및 그 category에서 무작위 줄(이름) 얻기\n",
        "def randomTrainingPair():\n",
        "    category = randomChoice(all_categories) # 랜덤한 category 명이 등장\n",
        "    line = randomChoice(category_lines[category]) # 해당 카테고리에 대한 line 도 랜덤하게 선택됨\n",
        "    return category, line"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZSIowZ_-aA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Category를 위한 One-hot 벡터\n",
        "def categoryTensor(category):\n",
        "    \n",
        "    # all_categories 는 리스트 형태이기 때문에 .index 로 인덱스를 불러와\n",
        "    # 그 기준으로 원-핫 텐서를 만들 수 있다\n",
        "    li = all_categories.index(category)\n",
        "    tensor = torch.zeros(1, n_categories)\n",
        "    tensor[0][li] = 1\n",
        "    return tensor\n",
        "\n",
        "# 입력을 위한 처음부터 마지막 문자(EOS 제외)까지의  One-hot 행렬\n",
        "def inputTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    \n",
        "    # 각 글자에 대한 원-핫 텐서 만들어줌\n",
        "    for li in range(len(line)):\n",
        "        letter = line[li]\n",
        "        tensor[li][0][all_letters.find(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# 목표를 위한 두번째 문자 부터 마지막(EOS) 까지의 LongTensor\n",
        "def targetTensor(line):\n",
        "\n",
        "    # 그 다음 글자를 꺼내줌 : 0이 아니라 1부터 꺼냄 \n",
        "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
        "    \n",
        "    # 제일 마지막엔 따로 <EOS> 를 위해 <EOS> 의 자리를 반환\n",
        "    letter_indexes.append(n_letters - 1) # EOS\n",
        "    return torch.LongTensor(letter_indexes)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g4IsiYMAIjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 임의의 Category에서 Category, Input, Target Tensor를 만듭니다.\n",
        "def randomTrainingExample():\n",
        "    \n",
        "    # 임의로 카테고리와 그 카테고리 중 한 단어를 뽑아옴\n",
        "    category, line = randomTrainingPair()\n",
        "\n",
        "    # 간단하게 카테고리 텐서를 만들어줌\n",
        "    category_tensor = categoryTensor(category)\n",
        "\n",
        "    # 인풋, 아웃풋 텐서를 별도로 만들어준 뒤 반환\n",
        "    input_line_tensor = inputTensor(line)\n",
        "    target_line_tensor = targetTensor(line)\n",
        "    return category_tensor, input_line_tensor, target_line_tensor"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BjJud6IAY-j",
        "colab_type": "text"
      },
      "source": [
        "## 네트워크 학습\n",
        "- 모든 단계에서 예측을 수행하므로 모든 단계에서 손실을 계산\n",
        "  - 마지막 출력만 사용하는 분류가 아니므로!\n",
        "- augograd 를 사용하면, 각 단계의 손실을 간단하게 합쳐 역전파 진행도 가능함!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMkShk9sAXmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "\n",
        "learning_rate = 0.0005\n",
        "\n",
        "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
        "    target_line_tensor.unsqueeze_(-1)\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(input_line_tensor.size(0)):\n",
        "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
        "        l = criterion(output, target_line_tensor[i])\n",
        "        loss += l\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item() / input_line_tensor.size(0)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM24iBbzAmXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time # 얼마나 걸리는지 확인하기 위함\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyHdFkpHAq14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}